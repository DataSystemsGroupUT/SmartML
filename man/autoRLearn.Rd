% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autoRLearn.R
\name{autoRLearn}
\alias{autoRLearn}
\title{Run smartML function for automatic Supervised Machine Learning.}
\usage{
autoRLearn(maxTime, directory, testDirectory, classCol = "class",
  selectedFeats = c(), vRatio = 0.1, preProcessF = "N",
  featuresToPreProcess = c(), nComp = NA, nModels = 3, option = 2,
  featureTypes = c(), interp = FALSE, missingOpr = FALSE)
}
\arguments{
\item{maxTime}{Float of the maximum time budget for reading dataset, preprocessing, calculating meta-features, Algorithm Selection & hyper-parameter tuning process only in minutes(Excluding Model Interpretability) - This is applicable in case of Option = 2 only.}

\item{directory}{String of the training dataset directory (SmartML accepts file formats arff/(csv with columns headers) ).}

\item{testDirectory}{String of the testing dataset directory (SmartML accepts file formats arff/(csv with columns headers) ).}

\item{classCol}{String of the name of the class label column in the dataset (default = 'class').}

\item{selectedFeats}{Vector of numbers of features columns to include from the training set and ignore the rest of columns - In case of empty vector, this means to include all features in the dataset file (default = c()).}

\item{vRatio}{Float of the validation set ratio that should be splitted out of the training set for the evaluation process (default = 0.1 --> 10\%).}

\item{preProcessF}{string containing the name of the preprocessing algorithm (default = 'N' --> no preprocessing):
\itemize{
\item "boxcox" - apply a Boxâ€“Cox transform and values must be non-zero and positive in all features,
\item "yeo-Johnson" - apply a Yeo-Johnson transform, like a BoxCox, but values can be negative,
\item "zv" - remove attributes with a zero variance (all the same value),
\item "center" - subtract mean from values,
\item "scale" - divide values by standard deviation,
\item "standardize" - perform both centering and scaling,
\item "normalize" - normalize values,
\item "pca" - transform data to the principal components,
\item "ica" - transform data to the independent components.
}}

\item{featuresToPreProcess}{Vector of number of features to perform the feature preprocessing on - In case of empty vector, this means to include all features in the dataset file (default = c()) - This vector should be a subset of \code{selectedFeats}.}

\item{nComp}{Integer of Number of components needed if either "pca" or "ica" feature preprocessors are needed.}

\item{nModels}{Integer representing the number of classifier algorithms that you want to select based on Meta-Learning and start to tune using Bayesian Optimization (default = 3).}

\item{option}{Integer representing either Classifier Algorithm Selection is needed only = 1 or Algorithm selection with its parameter tuning is required = 2 which is the default value.}

\item{featureTypes}{Vector of either 'numerical' or 'categorical' representing the types of features in the dataset (default = c() --> any factor or character features will be considered as categorical otherwise numerical).}

\item{interp}{Boolean representing if model interpretability (Feature Importance and Interaction) is needed or not (default = FALSE) This option will take more time budget if set to 1.}

\item{missingOpr}{Boolean variable represents either delete instances with missing values or apply imputation using "MICE" library which helps you imputing missing values with plausible data values that are drawn from a distribution specifically designed for each missing datapoint- (default = FALSE to delete instances).}
}
\value{
List of Results
\itemize{
\item "option=1" - Choosen Classifier Algorithms Names \code{clfs} with their parameters configurations \code{params}, Training DataFrame \code{TRData}, Test DataFrame \code{TEData} in case of \code{option=2},
\item "option=2" - Best classifier algorithm name found \code{clfs} with its parameters configuration \code{params}, , Training DataFrame \code{TRData}, Test DataFrame \code{TEData}, model variable \code{model}, performance on TestingSet \code{perf}, and Feature Importance \code{interpret$featImp} / Interaction \code{interpret$Interact} plots in case of interpretability \code{interp} = TRUE and chosen model is not knn.
}
}
\description{
Run the smartML main function for automatic classifier algorithm selection, and hyper-parameter tuning.
}
\examples{
\dontrun{
autoRLearn(1, 'sampleDatasets/car/train.arff', \\
'sampleDatasets/car/test.arff', option = 2, preProcessF = 'normalize')

result <- autoRLearn(10, 'sampleDatasets/shuttle/train.arff', 'sampleDatasets/shuttle/test.arff')
}

}
